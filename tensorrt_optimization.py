#!/usr/bin/env python3
"""
TensorRTä¼˜åŒ–å®ç°è„šæœ¬
"""
import os
import sys
import time
import torch
import numpy as np
from typing import Optional, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
now_dir = os.getcwd()
sys.path.append(now_dir)
sys.path.append("%s/GPT_SoVITS" % (now_dir))

try:
    import torch_tensorrt
    import tensorrt as trt
    TENSORRT_AVAILABLE = True
except ImportError:
    TENSORRT_AVAILABLE = False
    print("âš ï¸ TensorRTæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…TensorRT")

from GPT_SoVITS.TTS_infer_pack.TTS import TTS, TTS_Config

class TensorRTOptimizer:
    """TensorRTä¼˜åŒ–å™¨"""
    
    def __init__(self, tts_pipeline: TTS):
        self.tts_pipeline = tts_pipeline
        self.trt_vocoder = None
        self.original_vocoder = None
        self.optimization_config = {
            "precision": "fp16",
            "workspace_size": 1 << 30,  # 1GB
            "max_batch_size": 4,
            "dynamic_shapes": True
        }
    
    def check_tensorrt_availability(self) -> bool:
        """æ£€æŸ¥TensorRTæ˜¯å¦å¯ç”¨"""
        if not TENSORRT_AVAILABLE:
            print("âŒ TensorRTæœªå®‰è£…")
            return False
        
        if not torch.cuda.is_available():
            print("âŒ CUDAä¸å¯ç”¨")
            return False
        
        print("âœ… TensorRTç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        return True
    
    def get_vocoder_input_shape(self) -> tuple:
        """è·å–Vocoderè¾“å…¥å½¢çŠ¶"""
        version = self.tts_pipeline.configs.version
        
        if version == "v3":
            # BigVGANè¾“å…¥å½¢çŠ¶
            return (1, 100, 468)  # (batch, channels, time)
        else:
            # Generatorè¾“å…¥å½¢çŠ¶ (v4)
            return (1, 100, 500)  # (batch, channels, time)
    
    def get_dynamic_shapes(self) -> Dict[str, tuple]:
        """è·å–åŠ¨æ€å½¢çŠ¶é…ç½®"""
        base_shape = self.get_vocoder_input_shape()
        batch_size, channels, time_steps = base_shape
        
        return {
            "min_shape": (1, channels, 100),      # æœ€å°è¾“å…¥
            "opt_shape": (1, channels, time_steps), # æœ€ä¼˜è¾“å…¥
            "max_shape": (1, channels, 2000)      # æœ€å¤§è¾“å…¥
        }
    
    def convert_vocoder_to_tensorrt(self, precision: str = "fp16") -> bool:
        """è½¬æ¢Vocoderæ¨¡å‹åˆ°TensorRT"""
        if not self.check_tensorrt_availability():
            return False
        
        try:
            print("ğŸ”„ å¼€å§‹è½¬æ¢Vocoderæ¨¡å‹åˆ°TensorRT...")
            
            # ä¿å­˜åŸå§‹æ¨¡å‹
            self.original_vocoder = self.tts_pipeline.vocoder
            
            # è·å–è¾“å…¥å½¢çŠ¶
            input_shape = self.get_vocoder_input_shape()
            dynamic_shapes = self.get_dynamic_shapes()
            
            # è®¾ç½®TensorRTé…ç½®
            if self.optimization_config["dynamic_shapes"]:
                trt_input = torch_tensorrt.Input(
                    min_shape=dynamic_shapes["min_shape"],
                    opt_shape=dynamic_shapes["opt_shape"],
                    max_shape=dynamic_shapes["max_shape"]
                )
            else:
                trt_input = torch_tensorrt.Input(input_shape)
            
            # è®¾ç½®ç²¾åº¦
            if precision == "fp16":
                enabled_precisions = [torch.float16]
            else:
                enabled_precisions = [torch.float32]
            
            # è½¬æ¢æ¨¡å‹
            self.trt_vocoder = torch_tensorrt.compile(
                self.original_vocoder,
                inputs=[trt_input],
                enabled_precisions=enabled_precisions,
                workspace_size=self.optimization_config["workspace_size"],
                max_batch_size=self.optimization_config["max_batch_size"]
            )
            
            print("âœ… Vocoderæ¨¡å‹è½¬æ¢æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è½¬æ¢å¤±è´¥: {e}")
            return False
    
    def benchmark_performance(self, num_runs: int = 100) -> Dict[str, Any]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        if self.trt_vocoder is None:
            print("âŒ TensorRTæ¨¡å‹æœªåˆå§‹åŒ–")
            return {}
        
        print(f"ğŸ§ª å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯• ({num_runs} æ¬¡è¿è¡Œ)...")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        input_shape = self.get_vocoder_input_shape()
        test_input = torch.randn(input_shape).cuda()
        
        # æµ‹è¯•åŸå§‹æ¨¡å‹
        print("ğŸ“Š æµ‹è¯•åŸå§‹æ¨¡å‹...")
        torch.cuda.synchronize()
        start_time = time.perf_counter()
        
        for _ in range(num_runs):
            with torch.no_grad():
                _ = self.original_vocoder(test_input)
        
        torch.cuda.synchronize()
        original_time = time.perf_counter() - start_time
        
        # æµ‹è¯•TensorRTæ¨¡å‹
        print("ğŸ“Š æµ‹è¯•TensorRTæ¨¡å‹...")
        torch.cuda.synchronize()
        start_time = time.perf_counter()
        
        for _ in range(num_runs):
            with torch.no_grad():
                _ = self.trt_vocoder(test_input)
        
        torch.cuda.synchronize()
        trt_time = time.perf_counter() - start_time
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        speedup = original_time / trt_time
        throughput_original = num_runs / original_time
        throughput_trt = num_runs / trt_time
        
        results = {
            "original_time": original_time,
            "trt_time": trt_time,
            "speedup": speedup,
            "throughput_original": throughput_original,
            "throughput_trt": throughput_trt,
            "throughput_improvement": throughput_trt / throughput_original,
            "time_reduction_percent": (1 - trt_time / original_time) * 100
        }
        
        print(f"ğŸ“ˆ æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"   åŸå§‹æ¨¡å‹æ—¶é—´: {original_time:.3f}s")
        print(f"   TensorRTæ—¶é—´: {trt_time:.3f}s")
        print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"   ååé‡æå‡: {results['throughput_improvement']:.2f}x")
        print(f"   æ—¶é—´å‡å°‘: {results['time_reduction_percent']:.1f}%")
        
        return results
    
    def test_audio_quality(self, num_tests: int = 10) -> Dict[str, Any]:
        """éŸ³é¢‘è´¨é‡æµ‹è¯•"""
        if self.trt_vocoder is None:
            print("âŒ TensorRTæ¨¡å‹æœªåˆå§‹åŒ–")
            return {}
        
        print(f"ğŸµ å¼€å§‹éŸ³é¢‘è´¨é‡æµ‹è¯• ({num_tests} æ¬¡æµ‹è¯•)...")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        input_shape = self.get_vocoder_input_shape()
        test_input = torch.randn(input_shape).cuda()
        
        quality_metrics = {
            "mse": [],
            "mae": [],
            "similarity": []
        }
        
        for i in range(num_tests):
            # ç”Ÿæˆæµ‹è¯•è¾“å…¥
            test_input = torch.randn(input_shape).cuda()
            
            # ç”ŸæˆéŸ³é¢‘
            with torch.no_grad():
                original_audio = self.original_vocoder(test_input)
                trt_audio = self.trt_vocoder(test_input)
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            mse = torch.mean((original_audio - trt_audio) ** 2)
            mae = torch.mean(torch.abs(original_audio - trt_audio))
            similarity = 1 - mae.item()
            
            quality_metrics["mse"].append(mse.item())
            quality_metrics["mae"].append(mae.item())
            quality_metrics["similarity"].append(similarity)
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {
            "avg_mse": np.mean(quality_metrics["mse"]),
            "avg_mae": np.mean(quality_metrics["mae"]),
            "avg_similarity": np.mean(quality_metrics["similarity"]),
            "std_mse": np.std(quality_metrics["mse"]),
            "std_mae": np.std(quality_metrics["mae"]),
            "std_similarity": np.std(quality_metrics["similarity"])
        }
        
        print(f"ğŸµ éŸ³é¢‘è´¨é‡æµ‹è¯•ç»“æœ:")
        print(f"   å¹³å‡MSE: {avg_metrics['avg_mse']:.6f} Â± {avg_metrics['std_mse']:.6f}")
        print(f"   å¹³å‡MAE: {avg_metrics['avg_mae']:.6f} Â± {avg_metrics['std_mae']:.6f}")
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_metrics['avg_similarity']:.4f} Â± {avg_metrics['std_similarity']:.4f}")
        
        return avg_metrics
    
    def save_optimized_model(self, save_path: str) -> bool:
        """ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹"""
        if self.trt_vocoder is None:
            print("âŒ TensorRTæ¨¡å‹æœªåˆå§‹åŒ–")
            return False
        
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            # ä¿å­˜æ¨¡å‹
            torch.save(self.trt_vocoder.state_dict(), save_path)
            print(f"âœ… TensorRTæ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def load_optimized_model(self, load_path: str) -> bool:
        """åŠ è½½ä¼˜åŒ–åçš„æ¨¡å‹"""
        if not os.path.exists(load_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {load_path}")
            return False
        
        try:
            # åŠ è½½æ¨¡å‹
            self.trt_vocoder.load_state_dict(torch.load(load_path))
            print(f"âœ… TensorRTæ¨¡å‹å·²åŠ è½½: {load_path}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def integrate_with_tts(self) -> bool:
        """é›†æˆåˆ°TTSç®¡é“"""
        if self.trt_vocoder is None:
            print("âŒ TensorRTæ¨¡å‹æœªåˆå§‹åŒ–")
            return False
        
        try:
            # æ›¿æ¢åŸå§‹vocoder
            self.tts_pipeline.vocoder = self.trt_vocoder
            print("âœ… TensorRTæ¨¡å‹å·²é›†æˆåˆ°TTSç®¡é“")
            return True
            
        except Exception as e:
            print(f"âŒ é›†æˆå¤±è´¥: {e}")
            return False
    
    def restore_original_model(self) -> bool:
        """æ¢å¤åŸå§‹æ¨¡å‹"""
        if self.original_vocoder is None:
            print("âŒ åŸå§‹æ¨¡å‹æœªä¿å­˜")
            return False
        
        try:
            self.tts_pipeline.vocoder = self.original_vocoder
            print("âœ… å·²æ¢å¤åŸå§‹æ¨¡å‹")
            return True
            
        except Exception as e:
            print(f"âŒ æ¢å¤å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ TensorRTä¼˜åŒ–å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥TensorRTå¯ç”¨æ€§
    if not TENSORRT_AVAILABLE:
        print("âŒ TensorRTæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…TensorRT")
        print("å®‰è£…å‘½ä»¤:")
        print("  pip install tensorrt")
        print("  æˆ–")
        print("  conda install -c conda-forge tensorrt")
        return
    
    # åˆå§‹åŒ–TTSç®¡é“
    print("ğŸ“¦ åˆå§‹åŒ–TTSç®¡é“...")
    try:
        config_path = "GPT_SoVITS/configs/tts_infer.yaml"
        tts_config = TTS_Config(config_path)
        tts_pipeline = TTS(tts_config)
        print(f"âœ… TTSç®¡é“åˆå§‹åŒ–æˆåŠŸ (ç‰ˆæœ¬: {tts_config.version})")
    except Exception as e:
        print(f"âŒ TTSç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = TensorRTOptimizer(tts_pipeline)
    
    # è½¬æ¢æ¨¡å‹
    print("\nğŸ”„ å¼€å§‹æ¨¡å‹è½¬æ¢...")
    if not optimizer.convert_vocoder_to_tensorrt():
        print("âŒ æ¨¡å‹è½¬æ¢å¤±è´¥")
        return
    
    # æ€§èƒ½æµ‹è¯•
    print("\nğŸ§ª å¼€å§‹æ€§èƒ½æµ‹è¯•...")
    performance_results = optimizer.benchmark_performance(num_runs=50)
    
    # è´¨é‡æµ‹è¯•
    print("\nğŸµ å¼€å§‹è´¨é‡æµ‹è¯•...")
    quality_results = optimizer.test_audio_quality(num_tests=5)
    
    # ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜ä¼˜åŒ–æ¨¡å‹...")
    save_path = "optimized_models/trt_vocoder.pth"
    optimizer.save_optimized_model(save_path)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“Š ä¼˜åŒ–æŠ¥å‘Š")
    print("=" * 50)
    print(f"æ¨¡å‹ç‰ˆæœ¬: {tts_config.version}")
    print(f"ä¼˜åŒ–ç²¾åº¦: {optimizer.optimization_config['precision']}")
    print(f"å·¥ä½œç©ºé—´å¤§å°: {optimizer.optimization_config['workspace_size'] / (1<<30):.1f}GB")
    
    if performance_results:
        print(f"\næ€§èƒ½æå‡:")
        print(f"  åŠ é€Ÿæ¯”: {performance_results['speedup']:.2f}x")
        print(f"  ååé‡æå‡: {performance_results['throughput_improvement']:.2f}x")
        print(f"  æ—¶é—´å‡å°‘: {performance_results['time_reduction_percent']:.1f}%")
    
    if quality_results:
        print(f"\nè´¨é‡æŒ‡æ ‡:")
        print(f"  å¹³å‡ç›¸ä¼¼åº¦: {quality_results['avg_similarity']:.4f}")
        print(f"  å¹³å‡MSE: {quality_results['avg_mse']:.6f}")
    
    print("\nâœ… ä¼˜åŒ–å®Œæˆ!")

if __name__ == "__main__":
    main() 
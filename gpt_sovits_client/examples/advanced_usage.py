#!/usr/bin/env python3
"""
GPT-SoVITS Client SDK - é«˜çº§ä½¿ç”¨ç¤ºä¾‹
"""

import os
from gpt_sovits_client import (
    GPTSoVITSClient, 
    TTSRequest, 
    LanguageType, 
    TextSplitMethod
)

def advanced_usage_example():
    """é«˜çº§ä½¿ç”¨ç¤ºä¾‹"""
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = GPTSoVITSClient(base_url="http://localhost:9880", timeout=300)
    
    # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
    if not client.health_check():
        print("âŒ GPT-SoVITSæœåŠ¡æœªè¿è¡Œ")
        return
    
    print("âœ… GPT-SoVITSæœåŠ¡è¿è¡Œæ­£å¸¸")
    
    # å‚è€ƒéŸ³é¢‘æ–‡ä»¶
    ref_audio = "sample.wav"
    if not os.path.exists(ref_audio):
        print(f"âŒ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {ref_audio}")
        return
    
    # ç¤ºä¾‹1: ä½¿ç”¨TTSRequestå¯¹è±¡è¿›è¡Œç²¾ç¡®æ§åˆ¶
    print("\nğŸ“ ç¤ºä¾‹1: ä½¿ç”¨TTSRequestå¯¹è±¡")
    request1 = TTSRequest(
        text="è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨TTSRequestå¯¹è±¡çš„æµ‹è¯•ï¼Œå¯ä»¥ç²¾ç¡®æ§åˆ¶æ‰€æœ‰å‚æ•°ã€‚",
        ref_audio_path=ref_audio,
        text_lang=LanguageType.ALL_ZH,
        text_split_method=TextSplitMethod.CUT5,
        top_k=5,
        top_p=1.0,
        temperature=1.0,
        speed_factor=1.0,
        repetition_penalty=1.35,
        parallel_infer=True
    )
    
    response1 = client.synthesize(request1)
    if response1.success:
        print(f"âœ… æˆåŠŸ: {response1.audio_path}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {response1.file_size/1024:.1f}KB")
    else:
        print(f"âŒ å¤±è´¥: {response1.message}")
    
    # ç¤ºä¾‹2: è¯­è¨€æ£€æµ‹åŠŸèƒ½
    print("\nğŸ“ ç¤ºä¾‹2: è¯­è¨€æ£€æµ‹åŠŸèƒ½")
    test_texts = [
        "Hello world",
        "ä½ å¥½ä¸–ç•Œ",
        "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ",
        "ì•ˆë…•í•˜ì„¸ìš” ì„¸ê³„",
        "Hello ä½ å¥½ world ä¸–ç•Œ",
        "Hello ã“ã‚“ã«ã¡ã¯ ä½ å¥½ ì•ˆë…•í•˜ì„¸ìš”"
    ]
    
    for text in test_texts:
        segments = client.detect_language_segments(text)
        is_mixed = client.is_mixed_language(text)
        primary_lang = client.get_primary_language(text)
        auto_lang = client.auto_detect_language(text)
        
        print(f"æ–‡æœ¬: {text}")
        print(f"  è¯­è¨€ç‰‡æ®µ: {segments}")
        print(f"  æ··åˆè¯­è¨€: {is_mixed}")
        print(f"  ä¸»è¦è¯­è¨€: {primary_lang}")
        print(f"  è‡ªåŠ¨æ£€æµ‹: {auto_lang.value}")
        print()
    
    # ç¤ºä¾‹3: æ‰¹é‡å¤„ç†
    print("\nğŸ“ ç¤ºä¾‹3: æ‰¹é‡å¤„ç†")
    requests = [
        TTSRequest(
            text="ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
            ref_audio_path=ref_audio,
            text_lang=LanguageType.ALL_ZH
        ),
        TTSRequest(
            text="Second test text",
            ref_audio_path=ref_audio,
            text_lang=LanguageType.EN
        ),
        TTSRequest(
            text="Hello ä½ å¥½ world ä¸–ç•Œ",
            ref_audio_path=ref_audio,
            text_lang=LanguageType.AUTO
        )
    ]
    
    responses = client.batch_synthesize(requests)
    for i, response in enumerate(responses, 1):
        if response.success:
            print(f"âœ… æ‰¹é‡ä»»åŠ¡{i}æˆåŠŸ: {response.audio_path}")
        else:
            print(f"âŒ æ‰¹é‡ä»»åŠ¡{i}å¤±è´¥: {response.message}")
    
    # ç¤ºä¾‹4: é”™è¯¯å¤„ç†
    print("\nğŸ“ ç¤ºä¾‹4: é”™è¯¯å¤„ç†")
    
    # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
    response_error1 = client.synthesize_text(
        text="æµ‹è¯•é”™è¯¯å¤„ç†",
        ref_audio_path="nonexistent.wav",
        text_lang=LanguageType.ALL_ZH
    )
    print(f"æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯: {response_error1.message}")
    
    # æµ‹è¯•ç©ºæ–‡æœ¬
    response_error2 = client.synthesize_text(
        text="",
        ref_audio_path=ref_audio,
        text_lang=LanguageType.ALL_ZH
    )
    print(f"ç©ºæ–‡æœ¬é”™è¯¯: {response_error2.message}")

if __name__ == "__main__":
    advanced_usage_example() 
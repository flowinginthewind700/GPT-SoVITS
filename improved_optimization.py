#!/usr/bin/env python3
"""
æ”¹è¿›çš„CUDAä¼˜åŒ–å»ºè®®
"""
import requests
import time

BASE_URL = "http://219.144.21.182:9880"

def warm_up_optimization():
    """é¢„çƒ­CUDAä¼˜åŒ–ï¼Œæå‡åç»­æ€§èƒ½"""
    print("ğŸ”¥ é¢„çƒ­CUDAä¼˜åŒ–...")
    
    warm_up_texts = [
        "é¢„çƒ­æµ‹è¯•ä¸€",
        "é¢„çƒ­æµ‹è¯•äºŒï¼Œç¨å¾®é•¿ä¸€ç‚¹çš„æ–‡æœ¬",
        "é¢„çƒ­æµ‹è¯•ä¸‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´é•¿çš„æ–‡æœ¬ç”¨äºé¢„çƒ­CUDA Graphå’ŒGPUå†…å­˜"
    ]
    
    for i, text in enumerate(warm_up_texts, 1):
        print(f"   é¢„çƒ­ {i}/3: ", end="", flush=True)
        
        test_data = {
            "text": text,
            "text_lang": "zh",
            "ref_audio_path": "voice/vivienne/sample.mp3", 
            "prompt_text": "Hello, this is a sample text.",
            "prompt_lang": "en",
            "temperature": 1.0,
            "speed_factor": 1.0,
            "sample_steps": 32
        }
        
        start_time = time.perf_counter()
        try:
            response = requests.post(f"{BASE_URL}/tts", json=test_data, timeout=60)
            end_time = time.perf_counter()
            
            if response.status_code == 200:
                print(f"âœ… {end_time - start_time:.2f}s")
            else:
                print("âŒ å¤±è´¥")
        except:
            print("âŒ å¼‚å¸¸")
        
        time.sleep(1)

def test_optimized_performance():
    """æµ‹è¯•é¢„çƒ­åçš„æ€§èƒ½"""
    print("\nğŸš€ æµ‹è¯•é¢„çƒ­åæ€§èƒ½...")
    
    test_texts = [
        "ç°åœ¨æµ‹è¯•ä¼˜åŒ–åçš„æ€§èƒ½",
        "ç»è¿‡é¢„çƒ­çš„CUDA Graphåº”è¯¥è¡¨ç°æ›´å¥½",
        "è¿™ä¸ªè¾ƒé•¿çš„æ–‡æœ¬ç”¨æ¥æµ‹è¯•åˆ†å—å¤„ç†çš„æ•ˆæœï¼ŒéªŒè¯ç³»ç»Ÿåœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶çš„ç¨³å®šæ€§å’Œé€Ÿåº¦æå‡"
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\næµ‹è¯• {i}: {text[:20]}... ({len(text)}å­—ç¬¦)")
        
        durations = []
        for run in range(3):
            test_data = {
                "text": text,
                "text_lang": "zh",
                "ref_audio_path": "voice/vivienne/sample.mp3",
                "prompt_text": "Hello, this is a sample text.", 
                "prompt_lang": "en",
                "temperature": 1.0,
                "speed_factor": 1.0,
                "sample_steps": 32
            }
            
            start_time = time.perf_counter()
            try:
                response = requests.post(f"{BASE_URL}/tts", json=test_data, timeout=60)
                end_time = time.perf_counter()
                duration = end_time - start_time
                
                if response.status_code == 200:
                    durations.append(duration)
                    chars_per_sec = len(text) / duration
                    print(f"   ç¬¬{run+1}æ¬¡: {duration:.2f}s ({chars_per_sec:.1f}å­—ç¬¦/s)")
                else:
                    print(f"   ç¬¬{run+1}æ¬¡: å¤±è´¥")
            except Exception as e:
                print(f"   ç¬¬{run+1}æ¬¡: å¼‚å¸¸ {e}")
            
            time.sleep(0.5)
        
        if durations:
            avg_duration = sum(durations) / len(durations)
            avg_chars_per_sec = len(text) / avg_duration
            print(f"   å¹³å‡: {avg_duration:.2f}s ({avg_chars_per_sec:.1f}å­—ç¬¦/s)")

def get_optimization_recommendations():
    """è·å–ä¼˜åŒ–å»ºè®®"""
    try:
        response = requests.get(f"{BASE_URL}/performance_stats")
        if response.status_code == 200:
            stats = response.json()
            
            print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            print("=" * 40)
            
            avg_tts_time = stats.get('avg_tts_time', 0)
            requests_per_sec = stats.get('requests_per_second', 0)
            
            if avg_tts_time > 3:
                print("âš ï¸ å¹³å‡TTSæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
                print("   - å‡å°chunk_sizeåˆ°300-400")
                print("   - å¢åŠ GPUé¢„çƒ­æ¬¡æ•°")
                print("   - æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ")
            
            if requests_per_sec < 0.5:
                print("âš ï¸ ååé‡è¾ƒä½ï¼Œå»ºè®®:")
                print("   - å¯ç”¨æ›´ç§¯æçš„CUDA Graphç¼“å­˜")
                print("   - è€ƒè™‘ä½¿ç”¨æ¨¡å‹é‡åŒ–(FP16)")
                print("   - ä¼˜åŒ–å†…å­˜ç®¡ç†")
            
            if stats.get('cuda_optimization_enabled', False):
                print("âœ… CUDAä¼˜åŒ–å·²å¯ç”¨")
                if not stats.get('optimization_initialized', False):
                    print("âš ï¸ ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–ï¼Œå»ºè®®é¢„çƒ­ç³»ç»Ÿ")
                else:
                    print("âœ… ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–")
            else:
                print("âŒ CUDAä¼˜åŒ–æœªå¯ç”¨")
                
    except Exception as e:
        print(f"âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯: {e}")

if __name__ == "__main__":
    print("ğŸ”§ CUDAä¼˜åŒ–æ€§èƒ½æ”¹è¿›æµ‹è¯•")
    print("=" * 50)
    
    # 1. é¢„çƒ­ä¼˜åŒ–
    warm_up_optimization()
    
    # 2. æµ‹è¯•é¢„çƒ­åæ€§èƒ½
    test_optimized_performance()
    
    # 3. è·å–ä¼˜åŒ–å»ºè®®
    get_optimization_recommendations()
    
    print("\n" + "=" * 50)
    print("ğŸ¯ æµ‹è¯•å®Œæˆ! å»ºè®®:")
    print("1. é¢„çƒ­ç³»ç»Ÿå¯ä»¥æå‡åç»­æ€§èƒ½")
    print("2. å¯ä»¥è€ƒè™‘è°ƒæ•´chunk_sizeå‚æ•°")
    print("3. é•¿æ–‡æœ¬å¤„ç†æ•ˆæœé€šå¸¸æ›´æ˜æ˜¾")